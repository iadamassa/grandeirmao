# ğŸ›¡ï¸ Monitor de Anomalias - Sistema de DetecÃ§Ã£o Inteligente

Sistema completo para **monitoramento de conteÃºdo web** com detecÃ§Ã£o automatizada de anomalias usando **InteligÃªncia Artificial**. O sistema combina um **painel de controle web**, **crawler inteligente** e **motor de anÃ¡lise com IA** para identificar conteÃºdo problemÃ¡tico em sites.

## ğŸ“‹ VisÃ£o Geral do Sistema

O **Monitor de Anomalias** Ã© uma soluÃ§Ã£o completa que:

- **Monitora sites** de forma automatizada
- **Detecta conteÃºdo problemÃ¡tico** usando IA (Ollama/LLM)
- **Classifica e categoriza** anomalias encontradas
- **Fornece interface** para configuraÃ§Ã£o e visualizaÃ§Ã£o
- **Processa em tempo real** usando filas RabbitMQ

## ğŸ—ï¸ Arquitetura do Sistema

O projeto Ã© composto por **4 componentes principais** que se comunicam atravÃ©s de **mensageria assÃ­ncrona** (RabbitMQ), permitindo **distribuiÃ§Ã£o horizontal** em mÃºltiplas mÃ¡quinas para alta performance e escalabilidade.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PAINEL WEB    â”‚    â”‚    CRAWLER      â”‚    â”‚  FINDANOMALIE   â”‚    â”‚    RABBITMQ     â”‚
â”‚  (Interface)    â”‚    â”‚  (ExtraÃ§Ã£o)     â”‚    â”‚   (AnÃ¡lise)     â”‚    â”‚   (Mensageria)  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Dashboard     â”‚â”€â”€â”€â–¶â”‚ â€¢ HTTP Client   â”‚â”€â”€â”€â–¶â”‚ â€¢ Ollama/LLM    â”‚â”€â”€â”€â–¶â”‚ â€¢ Filas         â”‚
â”‚ â€¢ ConfiguraÃ§Ã£o  â”‚    â”‚ â€¢ HTML Parser   â”‚    â”‚ â€¢ ClassificaÃ§Ã£o â”‚    â”‚ â€¢ Exchange      â”‚
â”‚ â€¢ RelatÃ³rios    â”‚    â”‚ â€¢ Link Extract  â”‚    â”‚ â€¢ DetecÃ§Ã£o IA   â”‚    â”‚ â€¢ Routing       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸŒ Arquitetura DistribuÃ­da

O sistema foi projetado para **processamento distribuÃ­do**, onde cada componente pode ser executado em **mÃ¡quinas diferentes**, conectando-se ao **RabbitMQ central** para coordenaÃ§Ã£o. Esta arquitetura oferece:

#### âœ… **Escalabilidade Horizontal**
- **MÃºltiplas instÃ¢ncias** de cada serviÃ§o em mÃ¡quinas diferentes
- **Load balancing** automÃ¡tico via filas RabbitMQ
- **AdiÃ§Ã£o dinÃ¢mica** de novos nÃ³s conforme demanda

#### âœ… **Alta Disponibilidade**
- **TolerÃ¢ncia a falhas**: Se uma mÃ¡quina falhar, outras continuam processando
- **RedundÃ¢ncia**: MÃºltiplas instÃ¢ncias dos mesmos serviÃ§os
- **Recovery automÃ¡tico**: Mensagens nÃ£o processadas sÃ£o redistribuÃ­das

#### âœ… **Performance Otimizada**
- **Processamento paralelo**: MÃºltiplos crawlers e analisadores simultaneamente
- **EspecializaÃ§Ã£o por hardware**: IA em GPUs, crawling em CPUs otimizadas
- **Balanceamento inteligente** de carga entre nÃ³s

### ğŸ”„ ComunicaÃ§Ã£o via Mensageria

Todos os componentes se comunicam **exclusivamente atravÃ©s do RabbitMQ**, eliminando dependÃªncias diretas e permitindo distribuiÃ§Ã£o:

```
ğŸ¢ MÃQUINA 1 - Controle           ğŸ¢ MÃQUINA 2 - Crawling          ğŸ¢ MÃQUINA 3 - AnÃ¡lise IA
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     PAINEL WEB      â”‚          â”‚     CRAWLER #1      â”‚          â”‚   FINDANOMALIE #1   â”‚
â”‚                     â”‚          â”‚                     â”‚          â”‚                     â”‚
â”‚ â€¢ Interface Admin   â”‚          â”‚ â€¢ ExtraÃ§Ã£o Web      â”‚          â”‚ â€¢ AnÃ¡lise Ollama    â”‚
â”‚ â€¢ Dashboard         â”‚          â”‚ â€¢ HTML Parsing      â”‚          â”‚ â€¢ DetecÃ§Ã£o IA       â”‚
â”‚ â€¢ PostgreSQL        â”‚          â”‚                     â”‚          â”‚ â€¢ GPU Dedicada      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                â”‚                                â”‚
          â”‚                                â”‚                                â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚                           RABBITMQ CENTRAL                                â”‚
    â”‚                        ğŸ¢ MÃQUINA 4 - Mensageria                         â”‚
    â”‚                                                                           â”‚
    â”‚  ğŸ“¨ crawl-requests              ğŸ“¨ pages-processed       ğŸ“¨ links-analysed â”‚
    â”‚  â”œâ”€ Queue: Trabalhos            â”œâ”€ Queue: PÃ¡ginas       â”œâ”€ Queue: Results â”‚  
    â”‚  â”œâ”€ Routing: por prioridade     â”œâ”€ Load Balance         â”œâ”€ Persistence     â”‚
    â”‚  â””â”€ Multiple consumers          â””â”€ MÃºltiplos workers    â””â”€ Ack garantido   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–²                                â–²                                â–²
          â”‚                                â”‚                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     CRAWLER #2      â”‚          â”‚   FINDANOMALIE #2   â”‚          â”‚   FINDANOMALIE #3   â”‚
â”‚                     â”‚          â”‚                     â”‚          â”‚                     â”‚
â”‚ â€¢ Backup Instance   â”‚          â”‚ â€¢ CPU Instance      â”‚          â”‚ â€¢ Especializada     â”‚
â”‚ â€¢ Load Balancer     â”‚          â”‚ â€¢ Modelo Pequeno    â”‚          â”‚ â€¢ Modelo Grande     â”‚
â”‚ ğŸ¢ MÃQUINA 5        â”‚          â”‚ ğŸ¢ MÃQUINA 6        â”‚          â”‚ ğŸ¢ MÃQUINA 7        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š **Fluxo de Processamento DistribuÃ­do**

1. **ğŸ“ ConfiguraÃ§Ã£o** (Painel Web)
   - Admin configura **sites e assuntos** para monitoramento
   - Sistema **publica mensagens** `CrawlRequest` na fila
   - **Qualquer crawler disponÃ­vel** na rede pode processar

2. **ğŸ•·ï¸ Crawling DistribuÃ­do** (MÃºltiplos Crawlers)
   - Crawlers em **diferentes mÃ¡quinas** consomem fila `crawl-requests`
   - **Load balancing automÃ¡tico**: prÃ³ximo crawler disponÃ­vel pega o trabalho  
   - Cada crawler processa **independentemente** e publica `PageProcessedMessage`
   - **Failover**: Se um crawler falha, outros continuam processando

3. **ğŸ§  AnÃ¡lise IA DistribuÃ­da** (MÃºltiplos FindAnomalies)
   - InstÃ¢ncias de IA em **mÃ¡quinas especializadas** (GPU, CPU otimizada)
   - **EspecializaÃ§Ã£o por modelo**: Mistral em mÃ¡quina A, Llama3 em mÃ¡quina B
   - **Balanceamento inteligente**: AnÃ¡lises simples â†’ CPU, complexas â†’ GPU
   - Cada resultado Ã© **publicado de volta** para o Painel

4. **ğŸ“ˆ ConsolidaÃ§Ã£o** (Painel Web)
   - **Ãšnico painel centralizado** recebe todos os resultados
   - **Dashboard unificado** mostra progresso de todas as mÃ¡quinas
   - **Banco PostgreSQL** centralizado com todos os dados

### âš™ï¸ **ConfiguraÃ§Ã£o para DistribuiÃ§Ã£o**

Para executar componentes em **mÃ¡quinas diferentes**, altere apenas o **endereÃ§o do RabbitMQ**:

```bash
# MÃQUINA 1 - Painel Web + PostgreSQL + RabbitMQ
docker-compose up painel postgres rabbitmq redis

# MÃQUINA 2 - Crawlers (2 instÃ¢ncias)
export RABBITMQ_HOST=ip-da-maquina-1
docker-compose up --scale crawler=2 crawler

# MÃQUINA 3 - FindAnomalie GPU (1 instÃ¢ncia com GPU)  
export RABBITMQ_HOST=ip-da-maquina-1
docker-compose up findanomalie-gpu

# MÃQUINA 4 - FindAnomalie CPU (3 instÃ¢ncias CPU)
export RABBITMQ_HOST=ip-da-maquina-1  
docker-compose up --scale findanomalie=3 findanomalie
```

### ğŸ¯ **BenefÃ­cios da Arquitetura DistribuÃ­da**

- **âš¡ Performance**: Processamento paralelo em mÃºltiplas mÃ¡quinas
- **ğŸ“ˆ Escalabilidade**: Adicione mÃ¡quinas conforme crescimento
- **ğŸ›¡ï¸ ResiliÃªncia**: Falha de uma mÃ¡quina nÃ£o para o sistema
- **ğŸ’° OtimizaÃ§Ã£o de Custo**: Use hardware especializado (GPU para IA, CPU para crawling)
- **ğŸ”§ ManutenÃ§Ã£o**: Atualize componentes sem parar o sistema completo

### Fluxo de Processamento

```mermaid
graph LR
    A[UsuÃ¡rio configura sites] --> B[Painel envia para fila]
    B --> C[Crawler processa URLs]
    C --> D[Extrai conteÃºdo HTML]
    D --> E[Envia para anÃ¡lise]
    E --> F[IA analisa conteÃºdo]
    F --> G[Detecta anomalias]
    G --> H[Salva resultados]
    H --> I[Atualiza dashboard]
```

## ğŸ”§ Componentes Detalhados

### 1. ğŸ“Š **Painel Web** (Interface de GestÃ£o)

**LocalizaÃ§Ã£o:** `/Painel/`

Interface web completa para gestÃ£o e monitoramento do sistema.

**Tecnologias:**
- **Backend**: .NET 8, Entity Framework Core, MediatR (CQRS)
- **Frontend**: React 18, TypeScript, Tailwind CSS
- **Banco**: PostgreSQL (produÃ§Ã£o) / SQLite (desenvolvimento)
- **Cache**: Redis
- **AutenticaÃ§Ã£o**: JWT + ASP.NET Identity

**Funcionalidades:**
- âœ… **Dashboard** com grÃ¡ficos e mÃ©tricas em tempo real
- âœ… **GestÃ£o de Sites** para monitoramento
- âœ… **Categorias** para classificaÃ§Ã£o de sites
- âœ… **Assuntos de Pesquisa** para configurar detecÃ§Ãµes
- âœ… **RelatÃ³rios de Anomalias** com filtros avanÃ§ados
- âœ… **ExportaÃ§Ã£o para Excel** dos resultados
- âœ… **Sistema de usuÃ¡rios** com autenticaÃ§Ã£o segura

**Como executar:**
```bash
# Backend (.NET)
cd Painel/painel/api/AnomaliaMonitor.Solution/WebAPI/AnomaliaMonitor.WebAPI
dotnet run

# Frontend (React)
cd Painel/painel/frontend
npm install && npm start
```

**Acesso:** http://localhost:3000 (frontend) / https://localhost:7190 (backend)

---

### 2. ğŸ•·ï¸ **Crawler** (ExtraÃ§Ã£o de ConteÃºdo)

**LocalizaÃ§Ã£o:** `/crawler/`

ServiÃ§o responsÃ¡vel por navegar e extrair conteÃºdo dos sites configurados.

**Tecnologias:**
- **.NET 8** com HttpClient otimizado
- **HtmlAgilityPack** para parsing de HTML
- **MassTransit** para integraÃ§Ã£o com RabbitMQ
- **SemÃ¡foros** para controle de concorrÃªncia

**Funcionalidades:**
- ğŸ” **Crawling inteligente** com simulaÃ§Ã£o de comportamento humano
- ğŸ“„ **ExtraÃ§Ã£o de metadados** (tÃ­tulo, descriÃ§Ã£o, keywords)
- ğŸ”— **Descoberta automÃ¡tica** de links internos
- ğŸ“¤ **PublicaÃ§Ã£o automÃ¡tica** de pÃ¡ginas processadas
- âš¡ **Processamento assÃ­ncrono** com controle de rate limiting
- ğŸ›¡ï¸ **Headers dinÃ¢micos** para evitar bloqueios

**Processo de funcionamento:**
1. **Recebe** mensagem `CrawlRequest` via RabbitMQ
2. **Extrai** conteÃºdo HTML da URL solicitada
3. **Descobre** links internos automaticamente
4. **Processa** cada pÃ¡gina encontrada
5. **Publica** `PageProcessedMessage` para anÃ¡lise

**Como executar:**
```bash
cd crawler
dotnet restore
dotnet run
```

**Filas utilizadas:**
- **Entrada**: `crawl-requests` (recebe URLs para processar)
- **SaÃ­da**: `CrawlerWebApi.Models:PageProcessedMessage` (pÃ¡ginas processadas)

---

### 3. ğŸ§  **FindAnomalie** (DetecÃ§Ã£o com IA)

**LocalizaÃ§Ã£o:** `/findanomalie/`

Motor de anÃ¡lise que utiliza InteligÃªncia Artificial para detectar conteÃºdo problemÃ¡tico.

**Tecnologias:**
- **.NET 8** para processamento
- **Ollama** (LLM local) para anÃ¡lise inteligente
- **HtmlAgilityPack** para limpeza de conteÃºdo
- **MassTransit** para comunicaÃ§Ã£o assÃ­ncrona

**Funcionalidades:**
- ğŸ¤– **AnÃ¡lise com IA** usando modelos Ollama (Mistral, Llama3, etc.)
- ğŸ¯ **DetecÃ§Ã£o especializada** por assunto configurado
- ğŸ“Š **ClassificaÃ§Ã£o de confianÃ§a** com scoring
- ğŸ§¹ **Limpeza de HTML** para anÃ¡lise focada
- ğŸ“ **RelatÃ³rios detalhados** da anÃ¡lise
- ğŸ”„ **Processamento em lote** de mÃºltiplos assuntos

**Tipos de detecÃ§Ã£o configurÃ¡veis:**
- ConteÃºdo inadequado para menores
- Material relacionado a crimes
- Spam e phishing
- ConteÃºdo discriminatÃ³rio
- ViolaÃ§Ã£o de direitos autorais
- Outros conforme configuraÃ§Ã£o

**Processo de funcionamento:**
1. **Recebe** `PageProcessedMessage` do crawler
2. **Limpa** e extrai texto relevante do HTML
3. **Analisa** conteÃºdo usando IA/LLM configurado
4. **Classifica** anomalias por assunto pesquisado
5. **Publica** `LinkAnalysedMessage` com resultados

**Como executar:**
```bash
cd findanomalie
dotnet restore
dotnet run

# Requer Ollama rodando
ollama serve
ollama pull mistral  # ou llama3
```

---

### 4. ğŸ° **RabbitMQ** (Sistema de Mensageria)

**Papel:** ComunicaÃ§Ã£o assÃ­ncrona entre todos os componentes.

**Filas e mensagens:**

```
ğŸ“¨ FLUXO DE MENSAGENS:

1. crawl-requests
   â”œâ”€ Tipo: CrawlRequest
   â”œâ”€ Origem: Painel Web
   â”œâ”€ Destino: Crawler
   â””â”€ ConteÃºdo: { url, requestId, siteId, subjectsToResearch[] }

2. CrawlerWebApi.Models:PageProcessedMessage  
   â”œâ”€ Tipo: PageProcessedMessage
   â”œâ”€ Origem: Crawler
   â”œâ”€ Destino: FindAnomalie
   â””â”€ ConteÃºdo: { url, title, htmlContent, metaData, crawledAt }

3. CheckAnomaliaApi.Models:LinkAnalysedMessage
   â”œâ”€ Tipo: LinkAnalysedMessage
   â”œâ”€ Origem: FindAnomalie  
   â”œâ”€ Destino: Painel Web
   â””â”€ ConteÃºdo: { hasAnomalie, analysis, confidence, subject }
```

**ConfiguraÃ§Ã£o padrÃ£o:**
- **Host:** localhost:5672
- **UsuÃ¡rio:** guest/guest
- **Management UI:** http://localhost:15672

---

## ğŸš€ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o Completa

### ğŸ³ ExecuÃ§Ã£o com Docker Compose (Recomendado)

**PrÃ©-requisitos:**
- Docker e Docker Compose instalados

**ExecuÃ§Ã£o rÃ¡pida:**
```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd "Monitor Anomalias"

# Executar todos os serviÃ§os
docker-compose up -d

# Verificar status dos containers
docker-compose ps

# Acompanhar logs
docker-compose logs -f
```

**ServiÃ§os disponÃ­veis apÃ³s execuÃ§Ã£o:**
- **Frontend**: http://localhost:9003
- **API**: http://localhost:9000
- **Crawler**: http://localhost:9001  
- **FindAnomalie**: http://localhost:9002
- **RabbitMQ Management**: http://localhost:15672 (admin/admin123)
- **PostgreSQL**: localhost:5432 (postgres/postgres123)
- **Redis**: localhost:6379

**Comandos Ãºteis:**
```bash
# Parar todos os serviÃ§os
docker-compose down

# Remover volumes (dados)
docker-compose down -v

# Rebuild de um serviÃ§o especÃ­fico
docker-compose build api
docker-compose up -d api

# Ver logs de um serviÃ§o
docker-compose logs -f crawler
```

### ğŸ“‹ ExecuÃ§Ã£o Manual (Desenvolvimento)

### PrÃ©-requisitos

```bash
# Instalar dependÃªncias
- .NET 8 SDK
- Node.js 18+
- PostgreSQL Server
- RabbitMQ Server
- Redis Server
- Ollama (para IA)

# Instalar PostgreSQL
sudo apt install postgresql postgresql-contrib  # Ubuntu/Debian
brew install postgresql                         # macOS

# Instalar RabbitMQ
sudo apt install rabbitmq-server    # Ubuntu/Debian
brew install rabbitmq               # macOS

# Instalar Redis
sudo apt install redis-server       # Ubuntu/Debian
brew install redis                  # macOS

# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama pull mistral  # ou llama3
```

### Ordem de ExecuÃ§Ã£o

```bash
# 1. Iniciar serviÃ§os de infraestrutura
sudo systemctl start postgresql
sudo systemctl start rabbitmq-server
sudo systemctl start redis-server

# 2. Iniciar Ollama
ollama serve

# 3. Configurar banco PostgreSQL
sudo -u postgres createdb anomalia_monitor

# 4. Iniciar componentes (.NET)
cd crawler && dotnet run &
cd findanomalie && dotnet run &
cd Painel/api/WebAPI/AnomaliaMonitor.WebAPI && dotnet run &

# 5. Iniciar frontend React
cd Painel/frontend && npm install && npm start
```

### VerificaÃ§Ã£o dos ServiÃ§os

```bash
# Docker Compose
curl http://localhost:9000/api/test            # Painel API
curl http://localhost:9001/health              # Crawler
curl http://localhost:9002/health              # FindAnomalie
curl http://localhost:9003                     # Frontend

# ExecuÃ§Ã£o Manual
curl http://localhost:5000/api/crawler/health  # Crawler
curl http://localhost:8080/health              # FindAnomalie  
curl https://localhost:7190/api/test           # Painel API
curl http://localhost:3000                     # Frontend

# RabbitMQ Management
open http://localhost:15672
```

## ğŸ“Š Uso do Sistema

### 1. **ConfiguraÃ§Ã£o Inicial**

1. **Acesse** o painel web em:
   - Docker Compose: http://localhost:9003
   - ExecuÃ§Ã£o manual: http://localhost:3000
2. **FaÃ§a login** com: `teste@teste.com` / `Teste123`
3. **Configure assuntos** a serem pesquisados
4. **Adicione categorias** de sites
5. **Cadastre sites** para monitoramento

### 2. **Iniciando Monitoramento**

1. **Selecione um site** cadastrado
2. **Clique em "Iniciar Crawling"**
3. **Acompanhe o progresso** no dashboard
4. **Visualize resultados** na aba "Anomalias"

### 3. **AnÃ¡lise de Resultados**

- **Dashboard**: GrÃ¡ficos e mÃ©tricas gerais
- **Anomalias**: Lista detalhada com filtros
- **RelatÃ³rios**: ExportaÃ§Ã£o para Excel
- **Sites**: Status de cada site monitorado

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### ConfiguraÃ§Ã£o do Ollama

```json
// findanomalie/appsettings.json
{
  "Ollama": {
    "Url": "http://localhost:11434/api/generate",
    "Model": "mistral",  // ou "llama3"
    "Context": "Contexto personalizado para anÃ¡lise..."
  }
}
```

### ConfiguraÃ§Ã£o do RabbitMQ

```json
// Em todos os appsettings.json
{
  "ConnectionStrings": {
    "RabbitMQ": "amqp://usuario:senha@localhost:5672/"
  }
}
```

### ConfiguraÃ§Ã£o do Crawler

```csharp
// crawler/Services/CrawlerService.cs
private const int MaxConcurrency = 5;     // URLs simultÃ¢neas
private const int MinDelayMs = 500;       // Delay mÃ­nimo
private const int MaxDelayMs = 3000;      // Delay mÃ¡ximo
```

## ğŸ“ˆ Monitoramento e Logs

### Logs do Sistema

Cada componente gera logs detalhados:

```bash
# Crawler
ğŸš€ Iniciando extraÃ§Ã£o completa para: https://example.com
ğŸ” Extraindo dados de: https://example.com/page1
ğŸ“¤ PÃ¡gina enviada para fila de processamento

# FindAnomalie
ğŸ“„ Recebida pÃ¡gina processada: https://example.com/page1
ğŸ” AnÃ¡lise concluÃ­da - Anomalia detectada: true
ğŸ¯ ConfianÃ§a: 85.50%

# Painel
ğŸ“¨ LinkAnalysedMessage recebida para URL: https://example.com/page1
ğŸ’¾ Anomalia salva no banco de dados
```

### MÃ©tricas DisponÃ­veis

- **Taxa de processamento** (pÃ¡ginas/minuto)
- **Taxa de detecÃ§Ã£o** (anomalias encontradas)
- **Performance dos modelos** (tempo de anÃ¡lise)
- **Status das filas** RabbitMQ
- **EstatÃ­sticas de crawling** por site

## ğŸ”’ SeguranÃ§a

### CaracterÃ­sticas de SeguranÃ§a

- âœ… **AutenticaÃ§Ã£o JWT** para acesso ao painel
- âœ… **ValidaÃ§Ã£o de entrada** em todos os endpoints
- âœ… **Rate limiting** no crawler para evitar sobrecarga
- âœ… **SanitizaÃ§Ã£o HTML** antes da anÃ¡lise IA
- âœ… **Logs auditÃ¡veis** de todas as operaÃ§Ãµes
- âœ… **ComunicaÃ§Ã£o criptografada** entre componentes

### Boas PrÃ¡ticas Implementadas

- **User-Agent rotation** para crawler
- **Headers dinÃ¢micos** simulando navegador real
- **Delays aleatÃ³rios** entre requisiÃ§Ãµes
- **Retry policies** configurÃ¡veis
- **Timeout controls** em todas as operaÃ§Ãµes

## ğŸ› ï¸ Desenvolvimento e ExtensÃµes

### Estrutura de DiretÃ³rios

```
Monitor Anomalias/
â”œâ”€â”€ Painel/                          # Interface Web
â”‚   â”œâ”€â”€ painel/api/                 # Backend .NET
â”‚   â””â”€â”€ painel/frontend/            # Frontend React
â”œâ”€â”€ crawler/                        # ServiÃ§o de Crawling
â”‚   â”œâ”€â”€ Services/                   # LÃ³gica de extraÃ§Ã£o
â”‚   â””â”€â”€ Consumers/                  # Consumers RabbitMQ
â”œâ”€â”€ findanomalie/                   # Motor de AnÃ¡lise IA
â”‚   â”œâ”€â”€ Services/                   # ServiÃ§os de anÃ¡lise
â”‚   â””â”€â”€ Consumers/                  # Consumers RabbitMQ
â””â”€â”€ README.md                       # Esta documentaÃ§Ã£o
```

### Adicionando Novos Tipos de AnÃ¡lise

1. **Crie novo assunto** no painel web
2. **Configure exemplos** especÃ­ficos do assunto
3. **Ajuste prompt** no `HasAnomalieService.cs`
4. **Teste com pÃ¡ginas** conhecidas

### Integrando Novos Modelos IA

```csharp
// findanomalie/appsettings.json
{
  "Ollama": {
    "Model": "novo-modelo",
    "Url": "http://outro-servidor:11434/api/generate"
  }
}
```

## ğŸ“ Troubleshooting

### Problemas Comuns

**RabbitMQ nÃ£o conecta:**
```bash
sudo systemctl status rabbitmq-server
sudo systemctl restart rabbitmq-server
```

**Ollama nÃ£o responde:**
```bash
ollama list                    # Ver modelos instalados
ollama pull mistral            # Baixar modelo
curl http://localhost:11434    # Testar conexÃ£o
```

**Crawler nÃ£o processa:**
- Verificar filas no RabbitMQ Management
- Conferir logs do serviÃ§o
- Validar URLs configuradas

**IA nÃ£o detecta anomalias:**
- Conferir modelo Ollama carregado
- Verificar prompts configurados
- Testar com exemplos conhecidos

## ğŸ¤ ContribuiÃ§Ã£o

Para contribuir com o projeto:

1. **Fork** o repositÃ³rio
2. **Crie branch** para feature (`git checkout -b feature/nova-funcionalidade`)
3. **Commit** mudanÃ§as (`git commit -m 'Add nova funcionalidade'`)
4. **Push** para branch (`git push origin feature/nova-funcionalidade`)
5. **Abra Pull Request**

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a **MIT**. Veja o arquivo `LICENSE` para detalhes.

## ğŸ†˜ Suporte

Para dÃºvidas ou problemas:

- **Issues**: Abra uma issue no repositÃ³rio
- **DocumentaÃ§Ã£o**: Consulte os READMEs especÃ­ficos de cada componente
- **Logs**: Sempre consulte os logs dos serviÃ§os para diagnÃ³stico

---

**ğŸ›¡ï¸ Desenvolvido para monitoramento defensivo e identificaÃ§Ã£o de conteÃºdo problemÃ¡tico na web.**